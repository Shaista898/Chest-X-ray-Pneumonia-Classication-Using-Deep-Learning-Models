# Deep Learning CEP Project - Chest X-ray Pneumonia Classification
# Dataset: Chest X-ray Pneumonia (Kaggle)
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, callbacks, optimizers
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, Dropout,GlobalAveragePooling1D, LayerNormalization, MultiHeadAttention
from tensorflow.keras.models import Model
from tensorflow.keras.applications import Xception, ResNet50
from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from sklearn.metrics import classification_report, confusion_matrix

# Mount Kaggle and download dataset automatically
!pip install -q kaggle
import json
from google.colab import files


# Upload kaggle.json (Kaggle API key)
uploaded = files.upload()
os.makedirs("/root/.kaggle", exist_ok=True)
with open("/root/.kaggle/kaggle.json", "wb") as f: f.write(uploaded['kaggle.json'])
os.chmod("/root/.kaggle/kaggle.json", 0o600)

# Download Chest X-ray dataset
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
!unzip -q chest-xray-pneumonia.zip -d /content

# Phase 1: Dataset Selection and Preprocessing
img_height, img_width = 299, 299
batch_size = 16
dataset_path = '/content/chest_xray'
train_dir = os.path.join(dataset_path, 'train')
val_dir = os.path.join(dataset_path, 'val')
test_dir = os.path.join(dataset_path, 'test')

# Generic data preprocessing
datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, zoom_range=0.2,
horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)
train_data = datagen.flow_from_directory(train_dir, target_size=(img_height, img_width),
batch_size=batch_size, class_mode='binary')
val_data = test_datagen.flow_from_directory(val_dir, target_size=(img_height, img_width),
batch_size=batch_size, class_mode='binary')
test_data = test_datagen.flow_from_directory(test_dir, target_size=(img_height, img_width),
batch_size=batch_size, class_mode='binary', shuffle=False)

# Compute class weights
from sklearn.utils import class_weight
labels = train_data.classes
class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)
class_weights = dict(enumerate(class_weights))
print("Class Weights:", class_weights)

# Build CNN model
cnn_model = models.Sequential([
layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
layers.MaxPooling2D(),
layers.Dropout(0.15),
layers.Conv2D(64, (3, 3), activation='relu'),
layers.MaxPooling2D(),
layers.Dropout(0.25),
layers.Conv2D(128, (3, 3), activation='relu'),
layers.MaxPooling2D(),
layers.Dropout(0.4),
layers.Flatten(),
layers.Dense(128, activation='relu'),
layers.Dropout(0.5),
layers.Dense(1, activation='sigmoid')])
cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Callbacks
early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)

# Train CNN
cnn_history = cnn_model.fit(
train_data,
epochs=10,
validation_data=val_data,
callbacks=[early_stop, reduce_lr],
class_weight=class_weights)

# Plot training history
def plot_history(history, title):
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title(f'{title} Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{title} Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

plot_history(cnn_history, "CNN")

# Evaluate CNN model
def evaluate_model(model, test_data, name):
    print(f"\nEvaluating {name} on test data:")
    loss, acc = model.evaluate(test_data)
    print(f"Test Accuracy: {acc:.4f}")

    y_pred = (model.predict(test_data) > 0.5).astype(int).reshape(-1)
    y_true = test_data.classes
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=test_data.class_indices.keys()))

evaluate_model(cnn_model, test_data, "CNN")

# Build ResNet50 model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height,
img_width, 3))
base_model.trainable = False
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)
resnet_model = Model(inputs=base_model.input, outputs=output)
resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Callbacks
early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)

# Train ResNet
resnet_history = resnet_model.fit(
train_data,
epochs=10,
validation_data=val_data,
callbacks=[early_stop, reduce_lr],
class_weight=class_weights)

import matplotlib.pyplot as plt

# Plot training history
def plot_history(history, title):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title(f'{title} Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{title} Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

# Call the function with your history object
plot_history(resnet_history, "ResNet50")


from sklearn.metrics import confusion_matrix, classification_report

# Evaluate ResNet model
def evaluate_model(model, test_data, name):
    print(f"\nEvaluating {name} on test data:")
    loss, acc = model.evaluate(test_data)
    print(f"Test Accuracy: {acc:.4f}")

    y_pred = (model.predict(test_data) > 0.5).astype(int).reshape(-1)
    y_true = test_data.classes

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_true, y_pred))

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=test_data.class_indices.keys()))

# Call the function
evaluate_model(resnet_model, test_data, "ResNet50")


# CNN with Transformer Architecture
cnn_input = Input(shape=(img_height, img_width, 3))
x = Conv2D(32, (3,3), activation='relu')(cnn_input)
x = MaxPooling2D()(x)
x = Conv2D(64, (3,3), activation='relu')(x)
x = MaxPooling2D()(x)
x = Conv2D(128, (3,3), activation='relu')(x)
x = MaxPooling2D()(x)
x = Reshape((-1, 128))(x)

attn = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)
x = LayerNormalization()(x + attn)
ff = Dense(128, activation='relu')(x)
x = LayerNormalization()(x + ff)

x = GlobalAveragePooling1D()(x)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)

transformer_model = Model(inputs=cnn_input, outputs=output)
transformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Callbacks
early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)

# Train CNN with Transformer
transformer_history = transformer_model.fit(
train_data,
epochs=10,
validation_data=val_data,)

# Plotting function
def plot_history(history, title):
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title(f'{title} Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{title} Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

# Plot for CNN with Transformer
plot_history(transformer_history, "CNN + Transformer")

from sklearn.metrics import confusion_matrix, classification_report

# Evaluation function
def evaluate_model(model, test_data, name):
    print(f"\nEvaluating {name} on test data:")
    loss, acc = model.evaluate(test_data)
    print(f"Test Accuracy: {acc:.4f}")

    y_pred = (model.predict(test_data) > 0.5).astype(int).reshape(-1)
    y_true = test_data.classes

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_true, y_pred))

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=test_data.class_indices.keys()))

# Evaluate CNN with Transformer
evaluate_model(transformer_model, test_data, "CNN + Transformer")


import matplotlib.pyplot as plt
import numpy as np
import random

# Re-initialize test_data if needed to start from beginning
test_data.reset()

# Collect all images and labels
test_images, test_labels = [], []

# Loop through all batches
for _ in range(len(test_data)):
    img_batch, label_batch = next(test_data)
    test_images.extend(img_batch)
    test_labels.extend(label_batch)

# Convert to arrays
test_images = np.array(test_images)
test_labels = np.array(test_labels).reshape(-1)

# Get predictions from the model
preds = (transformer_model.predict(test_images) > 0.5).astype(int).reshape(-1)

# Get class names
class_names = list(test_data.class_indices.keys())

# Randomly select 5 images
random_indices = random.sample(range(len(test_images)), 5)

# Plot predictions
plt.figure(figsize=(15, 5))
for i, idx in enumerate(random_indices):
    plt.subplot(1, 5, i + 1)
    plt.imshow(test_images[idx])
    true_label = class_names[int(test_labels[idx])]
    pred_label = class_names[int(preds[idx])]
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis('off')

plt.suptitle("Model Predictions on Test Images")
plt.show()
